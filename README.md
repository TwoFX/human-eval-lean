# Verified hand-written Lean solutions to HumanEval

[HumanEval] is a collection of small programming tasks originally intended as a benchmark for LLMs.
In this repo, we collect hand-written *formally verified* [Lean 4] solutions to these problems.

The idea is to build a small set of simple examples for verified software development using Lean.
It is inspired by [human-eval-verus], which does a similar thing for the Verus Rust verification
platform.

[HumanEval]: https://github.com/openai/human-eval
[Lean 4]: https://lean-lang.org/
[human-eval-verus]: https://github.com/secure-foundations/human-eval-verus